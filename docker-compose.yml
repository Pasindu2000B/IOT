version: '3.8'

services:
  
  mosquitto:
    image: eclipse-mosquitto:2.0
    container_name: mosquitto
    ports:
      - "1883:1883"
      - "9001:9001"
    volumes:
      - ./mqtt-broker/config:/mosquitto/config
      - ./mqtt-broker/data:/mosquitto/data
      - ./mqtt-broker/log:/mosquitto/log
    restart: always
    healthcheck:
      test: ["CMD", "mosquitto_pub", "-h", "localhost", "-t", "test", "-m", "test", "-u", "test", "-P", "test"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    ports:
      - "8086:8086"
    volumes:
      - ./influxdb/data:/var/lib/influxdb2
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: Pasindu Bimsara
      DOCKER_INFLUXDB_INIT_PASSWORD: abcdefgh
      DOCKER_INFLUXDB_INIT_ORG: Ruhuna_Eng
      DOCKER_INFLUXDB_INIT_BUCKET: New_Sensor
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: GO7pQ79-Vo-k6uwpQrMmJmITzLRHxyrFbFDrnRbz8PgZbLHKe5hpwNZCWi6Z_zolPRjn7jUQ6irQk-BPe3LK9Q==
    restart: always
    healthcheck:
      test: ["CMD", "influx", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  spark-master:
    build:
      context: ./spark-apps
      dockerfile: Dockerfile
    container_name: spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
    environment:
      SPARK_MODE: master
    volumes:
      - ./spark-apps:/opt/spark-apps
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    restart: always

  spark-worker-1:
    build:
      context: ./spark-apps
      dockerfile: Dockerfile
    container_name: spark-worker-1
    depends_on:
      - spark-master
    environment:
      SPARK_MASTER: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 2G
      SPARK_WORKER_CORES: 2
    volumes:
      - ./spark-apps:/opt/spark-apps
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    restart: always

  spark-worker-2:
    build:
      context: ./spark-apps
      dockerfile: Dockerfile
    container_name: spark-worker-2
    depends_on:
      - spark-master
    environment:
      SPARK_MASTER: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 2G
      SPARK_WORKER_CORES: 2
    volumes:
      - ./spark-apps:/opt/spark-apps
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    restart: always

  training-scheduler:
    build:
      context: ./spark-apps
      dockerfile: Dockerfile
    container_name: training-scheduler
    depends_on:
      - spark-master
      - influxdb
    environment:
      SPARK_MASTER: spark://spark-master:7077
    volumes:
      - ./spark-apps:/opt/spark-apps
      - ./run_monthly_training.sh:/run_monthly_training.sh
    command: >
      bash -c "
      apt-get update && apt-get install -y cron &&
      echo '0 0 1 * * /usr/bin/bash /run_monthly_training.sh >> /var/log/training.log 2>&1' | crontab - &&
      cron -f
      "
    restart: always

networks:
  default:
    name: iot-network