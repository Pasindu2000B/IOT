{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db87ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdbafbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "lookback = 1200\n",
    "horizon = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50089ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: ../AI-Model-Artifacts/\n",
      "‚úÖ Directory exists and is accessible.\n",
      "Items in directory:\n",
      "  - MinMax_Scaler.pkl\n",
      "  - model_best\n",
      "  - multi_vanilla_patchtst.pt\n",
      "  - Scaled_Test.npy\n",
      "  - Test.csv\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"../AI-Model-Artifacts/\"\n",
    "print(\"Base directory:\", base_dir)\n",
    "\n",
    "if os.path.exists(base_dir):\n",
    "    print(\"‚úÖ Directory exists and is accessible.\")\n",
    "    items = os.listdir(base_dir)\n",
    "    print(\"Items in directory:\")\n",
    "    for item in items:\n",
    "        print(f\"  - {item}\")\n",
    "else:\n",
    "    print(\"‚ùå Directory does not exist or is not accessible.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4021eb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Files Loaded\n"
     ]
    }
   ],
   "source": [
    "model_path  = os.path.join(base_dir, \"multi_vanilla_patchtst.pt\")\n",
    "scaler_path = os.path.join(base_dir, \"MinMax_Scaler.pkl\")\n",
    "X_test_path = os.path.join(base_dir, \"X_test.npy\")                  # Data From the DB\n",
    "print(\"üîÑ Files Loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e841e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded: (5560, 1200, 4)\n",
      "‚úÖ Input tensor shape: torch.Size([1, 5560, 1200, 4])\n"
     ]
    }
   ],
   "source": [
    "scaled_X_test = np.load(X_test_path)\n",
    "print(\"‚úÖ Data loaded:\", scaled_X_test.shape)\n",
    "\n",
    "X_last = scaled_X_test\n",
    "X_tensor = torch.tensor(X_last, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "print(\"‚úÖ Input tensor shape:\", X_tensor.shape)  # shape (1, 1200, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87cfb6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\### STUDIES ###\\# Computer Engineering\\Sem_08\\# FYP\\PROJECT\\Workflow\\Workflow_Test_1\\FYP-Machine-Condition-Prediction\\_fyp_wf_1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PatchTST model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the scaler\n",
    "with open(scaler_path, \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Load the model\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"‚úÖ PatchTST model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a92be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Or Inverse Scale\n",
    "# Choose what's suitable\n",
    "# Runs up to here without errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033998a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "with torch.no_grad():\n",
    "    outputs = model(past_values=X_tensor)\n",
    "    forecast = outputs.prediction_outputs.squeeze().cpu().numpy()\n",
    "\n",
    "print(\"‚úÖ Raw forecast stats:\")\n",
    "print(f\"Shape: {forecast.shape}\")\n",
    "print(f\"Min: {forecast.min()}, Max: {forecast.max()}\")\n",
    "print(f\"NaN count: {np.isnan(forecast).sum()}\")\n",
    "print(f\"NaN per feature: {np.isnan(forecast).sum(axis=0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad45d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_last.shape[1] if X_last.ndim == 2 else 1\n",
    "\n",
    "for feature_idx in range(num_features):\n",
    "    # Select single feature data\n",
    "    X_feature = X_last[:, feature_idx] if X_last.ndim == 2 else X_last\n",
    "    forecast_feature = forecast[:, feature_idx] if forecast.ndim == 2 else forecast\n",
    "\n",
    "    # Inverse transform to original scale\n",
    "    forecast_feature_scaled = forecast_feature.reshape(-1, 1)\n",
    "    feature_min = scaler.min_[feature_idx]\n",
    "    feature_scale = scaler.scale_[feature_idx]\n",
    "    forecast_feature_orig = forecast_feature_scaled * (1/feature_scale) - (feature_min/feature_scale)\n",
    "    forecast_feature_orig = forecast_feature_orig.flatten()\n",
    "\n",
    "    X_feature_scaled = X_feature.reshape(-1, 1)\n",
    "    X_feature_orig = X_feature_scaled * (1/feature_scale) - (feature_min/feature_scale)\n",
    "    X_feature_orig = X_feature_orig.flatten()\n",
    "\n",
    "    # Compute Tolerance Band in original scale\n",
    "    lowest_actual = np.min(X_feature_orig)\n",
    "    highest_actual = np.max(X_feature_orig)\n",
    "    band_half = (highest_actual - lowest_actual) / 10\n",
    "    band_lower = forecast_feature_orig - band_half\n",
    "    band_upper = forecast_feature_orig + band_half\n",
    "    print(f\"‚úÖ Feature_{feature_idx}: Computed tolerance band ¬±{band_half:.4f} (Original Scale)\")\n",
    "\n",
    "    # Plot in original scale\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.plot(\n",
    "        np.arange(lookback, lookback + horizon),\n",
    "        X_feature_orig,\n",
    "        color=\"green\",\n",
    "        linestyle=\"--\",\n",
    "        marker=\"o\",\n",
    "        label=\"Actual Lookback\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.arange(lookback, lookback + len(forecast_feature_orig)),\n",
    "        forecast_feature_orig,\n",
    "        color=\"red\",\n",
    "        linestyle=\":\",\n",
    "        marker=\"x\",\n",
    "        label=\"Model Forecast\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        np.arange(lookback, lookback + len(forecast_feature_orig)),\n",
    "        band_lower,\n",
    "        band_upper,\n",
    "        color='red',\n",
    "        alpha=0.2,\n",
    "        label=\"Forecast Tolerance Band\"\n",
    "    )\n",
    "    plt.xlabel(\"Time Steps\")\n",
    "    plt.ylabel(\"Feature Value (Original Scale)\")\n",
    "    plt.title(f\"Feature_{feature_idx} Forecast ‚Äî Actual vs Predicted Horizon with Tolerance Band\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_fyp_wf_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
