#!/bin/bash
# =============================================================================
# IOT Predictive Maintenance System - Deployment Script
# =============================================================================

set -e  # Exit on error

echo "==============================================="
echo "  IOT Predictive Maintenance System Setup"
echo "==============================================="
echo ""

# Step 1: Start Docker containers
echo "ğŸ“¦ Step 1: Starting Docker containers..."
docker-compose up -d

# Wait for services to be healthy
echo "â³ Waiting for services to start (30 seconds)..."
sleep 30

# Step 2: Check service health
echo ""
echo "ğŸ” Step 2: Checking service health..."
docker-compose ps

# Step 3: Setup Spark workers with Python dependencies
echo ""
echo "ğŸ“š Step 3: Installing Python dependencies on Spark workers..."
echo "   This may take 2-3 minutes..."

docker exec -u root spark-master bash -c "pip install --quiet numpy pandas influxdb-client torch torchvision --index-url https://download.pytorch.org/whl/cpu" &
PID1=$!

docker exec -u root spark-worker-1 bash -c "pip install --quiet numpy pandas influxdb-client torch torchvision --index-url https://download.pytorch.org/whl/cpu" &
PID2=$!

docker exec -u root spark-worker-2 bash -c "pip install --quiet numpy pandas influxdb-client torch torchvision --index-url https://download.pytorch.org/whl/cpu" &
PID3=$!

# Wait for all installations to complete
wait $PID1
wait $PID2
wait $PID3

echo "   âœ… All dependencies installed!"

# Step 4: Start data generation
echo ""
echo "ğŸ“Š Step 4: Starting sensor data generation..."
nohup python3 GenerateData.py > logs/generate_data.log 2>&1 &
echo $! > logs/generate_data.pid
echo "   âœ… Data generator started (PID: $(cat logs/generate_data.pid))"

# Step 5: Start MQTT to InfluxDB bridge
echo ""
echo "ğŸŒ‰ Step 5: Starting MQTT to InfluxDB bridge..."
chmod +x start_bridge.sh
./start_bridge.sh

# Step 6: Wait for data collection
echo ""
echo "â³ Step 6: Collecting initial data (2 minutes)..."
echo "   This allows the system to gather training data..."
sleep 120

# Step 7: Run initial distributed training
echo ""
echo "ğŸ¯ Step 7: Running initial distributed model training..."
docker exec spark-master bash -c "/opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --executor-memory 1g \
  --total-executor-cores 4 \
  --conf spark.executor.cores=2 \
  --conf spark.task.cpus=1 \
  --conf spark.python.worker.reuse=true \
  /opt/spark-apps/train_distributed.py"

# Step 8: Display summary
echo ""
echo "==============================================="
echo "  âœ… System Successfully Deployed!"
echo "==============================================="
echo ""
echo "ğŸ“Š Service URLs:"
echo "   â€¢ Spark Master UI:  http://localhost:8080"
echo "   â€¢ InfluxDB UI:      http://localhost:8086"
echo "   â€¢ MQTT Broker:      localhost:1883"
echo ""
echo "ğŸ“ Important Directories:"
echo "   â€¢ Models:           ./spark-apps/models/"
echo "   â€¢ Logs:             ./logs/"
echo ""
echo "ğŸ”§ Useful Commands:"
echo "   â€¢ View logs:        tail -f logs/bridge.log"
echo "   â€¢ Check status:     ./status.sh"
echo "   â€¢ Stop system:      ./stop.sh"
echo "   â€¢ Retrain models:   ./retrain.sh"
echo ""
echo "ğŸ“ Training Summary:"
docker exec spark-master ls -lh /opt/spark-apps/models/ | grep "^-" | tail -6
echo ""
echo "==============================================="
